初步想法是先对文本按句号分句，然后使用 HANLP 的关键词短语提取功能提取出每个句子中前 10 权重的关键词，然后在这些关键词中进行去重（即将被包含的关键词短语删除），最后将这些关键词按权重从高到低排序输出。这样就起到从任何领域提取实体的作用。而不需要预先定义专业领域的命名实体词典。

下一步做的对句子进行依存句法分析，根据依存句法分析结果，提取出名词短语和动词短语。然后将动词作为三元组中的关系（这一点后续可能要增强，因为只将动词作为关系，实际情况中也有名词等等情况可以作为三元组的关系），其次名词从过滤后的关键词中提取出主语和宾语，形成三元组。最后将三元组进行去重，输出最终的三元组。

修改：将依存句法分析与三元组提取分开，dependency_syntax.py 脚本将依存句法分析结果输出到文件 dependency_analysis.json 中，triple_extraction.py 脚本读取该文件进行三元组提取。

但是目前存在指代消解的问题需要解决。下一步的指代消解可以使用 HANLP 的指代消解功能。

已添加指代消解功能。

项目运行：
（1）先执行 python dependency_syntax.py 进行依存句法分析，生成文件 dependency_analysis.json。
（2）再执行 python coreference_resolution.py 进行指代消解，生成文件 coreference.json。该文件中包含了指代消解后的文本和对应的指代关系。
（3）再执行 python triple_extraction.py 进行三元组提取，生成文件 triples.json。该文件中包含了提取出的三元组。